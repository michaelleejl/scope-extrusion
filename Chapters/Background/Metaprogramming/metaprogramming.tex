\section{Metaprogramming}\label{section:metaprogramming-technical}
What is MacoCaml-style metaprogramming? This section provides an answer in two steps. \Cref{subsection:metaprogramming-motivation} motivates metaprogramming, by illustrating the challenge of writing code that is both fast and maintainable. \Cref{subsection:metaprogramming-design} considers the design space of metaprogramming, highlighting decisions made by the MacoCaml designers.

\subsection{Metaprogramming for Fast and Maintainable Code}\label{subsection:metaprogramming-motivation}

Metaprogramming helps programmers write fast and maintainable code. How does one write fast and maintainable code? Programmer skill is insufficient, because maintainability and efficiency are in constant tension. 

To illustrate this tension, consider an example from the \texttt{JAX} machine learning library (adapted to \texttt{OCaml}): computing the gradient of a differentiable function as part of backpropagation over a neural network. More precisely, assume a type \mintinline{ocaml}{diff} of differentiable functions (for simplicity, comprising only polynomials and composition)

\begin{ocaml}
type diff = Poly of int list 
          | Compose of diff * diff
\end{ocaml}
For example, the following expression represents $2(x^2 + 2x) + 4$. 
% or $\cos \circ \tanh(x) $ depending on if the argument is \mintinline{ocaml}{true} or \mintinline{ocaml}{false}. 
\begin{ocaml}
Compose(Poly([1 ; 2 ; 0]), Poly([2 ; 4]))
\end{ocaml}

The \mintinline{ocaml}{app: diff -> int -> int} function evaluates elements of type \mintinline{ocaml}{diff}. 

\begin{ocaml}
let rec app (f: diff) (x: int) = 
  let rec app_poly (cs: int list) (x : int) (acc: int) = match cs with 
    | [] -> acc 
    | c::cs -> app_poly cs x (c + (x * acc)) 
  in match f with 
    | Poly(cs)      -> match cs with 
                      | [] -> 0
                      | c::cs -> app_poly cs x c
    | Compose(g, h) -> app h (app g x)
\end{ocaml}

The challenge is to write a function \mintinline{ocaml}{grad: diff -> int -> int} that computes the gradient of its first argument with respect to its second. The \mintinline{ocaml}{grad_main} function (\Cref{listing:ocaml-grad-main}) is one maintainable way to compute gradients: 

\begin{code}
\begin{ocamllst}
let rec grad_main (f: diff) (x: int) = 
  let grad_poly (cs: int list) (x: int) = 
    let grad_p c (a, b) = (c * b :: a, b + 1) 
    let (res, _) = List.fold_right grad_p cs ([], 0) in 
    app Poly(remove_last res) x (*remove_last removes the last element of a list*)
  in match f with
    | Poly(cs)      -> grad_poly cs x
    | Compose(g, h) -> grad_main g x * grad_main h (app g x)

\end{ocamllst}
\captionof{listing}{A maintainable implementation of \mintinline{ocaml}{grad}}%
\label{listing:ocaml-grad-main}
\end{code}

% Applying \mintinline{ocaml}{grad_main} to $2(x^2 + 2x + 3)^2 + 4$, we obtain
% \begin{ocaml}
% Mul(Poly([2.0 ; 2.0]), Compose([1.0 ; 2.0 ; 3.0], Poly([4.0])))
% \end{ocaml}
% may not be the most efficient implementation. Performing a \mintinline{ocaml}{match} on every recursive call might result in expensive branches. If \mintinline{ocaml}{x} is a vector, and the weights of a Poly are vectors, then \mintinline{ocaml}{grad_main} could hide opportunities for cache prefetching.

If the function to be differentiated (\mintinline{ocaml}{f}) is known in advance, for example, \mintinline{ocaml}{f} $= 2(x^2 + 2x) + 4$, then this approach is inefficient. Instead, \mintinline{ocaml}{grad} could be specialised to a more efficient \mintinline{ocaml}{grad_spec} function (\Cref{listing:ocaml-grad-fast}), whose body is simply a hardcoded equation:

\begin{code}
\begin{ocamllst}
let grad_spec x = 4 * x + 4
\end{ocamllst}
\captionof{listing}{An implementation of \mintinline{ocaml}{grad}, specialised to \mintinline{ocaml}{f} $=2(x^2 + 2x) + 4$}
\label{listing:ocaml-grad-fast}
\end{code}    

What if there were multiple such \mintinline{ocaml}{f}s? We could use \mintinline{ocaml}{grad_main} to parameterise over the possible \mintinline{ocaml}{f}s, relying on one implementation. Abstraction centralises implementations, reducing maintenance costs, but resulting in inefficiency. Alternatively, we could hardcode one variant of \mintinline{ocaml}{grad_spec} for each \mintinline{ocaml}{f}, creating an army of efficient functions. Specialisation applies known arguments in advance, creating opportunities for optimisation, but at the cost of maintainability. 

The tension between maintainability (abstraction) and efficiency (specialisation) has also been observed in other works on metaprogramming, in domains such as regex matching \citep{tratt-2008}, parsing \citep{yallop-2023}, linking \citep{servetto-2013}, statistical modelling \citep{wickham-2019}, and hardware design \citep{vandebon-2021}.

A better approach might therefore be to write maintainable code, delegating the responsibility of optimisation to the compiler. While this suffices for many cases, relying solely on compiler optimisation can be insufficient. The compiler may not implement the desired optimisations. While compiler engineers might have an economic incentive to write optimisations for the machine learning community, this may not be true for less lucrative domains \citep{robinson-01}. Even in machine learning, many libraries are built on top of existing languages, like \texttt{Python}, which might not perform the desired optimisations. Further, even if the compiler does implement the optimisation, the programmer has little control over the optimisation process: the compiler may not optimise as frequently as desired, or optimise in ways that do not meet all of the programmer's desiderata (for example, by inflating binary sizes). Moreover, the optimisation process may be sensitive to small changes in the source code.

How does one write maintainable and efficient code, \textbf{when one is not certain that the compiler will optimise one's code exactly as desired}?

One answer, and the approach taken by \texttt{JAX} \citep{jax-grad-metaprogramming}, is metaprogramming, which gives users the ability to perform code-generation. Programmers may thus take matters into their own hands: manually generating optimised code when the compiler may not automatically do so for them. 
% The \mintinline{ocaml}{grad} function in \texttt{JAX} uses metaprogramming for precisely this purpose \citep{jax-grad-metaprogramming}.

\subsubsection{The Mechanics of Metaprogramming}
Metaprogramming allows for code that, when executed, generates code. Thus, it can be utilised to write a function, \mintinline{ocaml}{grad_gen}, which resembles \mintinline{ocaml}{grad_main} (inheriting its maintainability), but that generates a program which resembles \mintinline{ocaml}{grad_spec} (inheriting its efficiency). 

\Cref{listing:ocaml-pow-gen} presents the metaprogrammed \mintinline{ocaml}{grad_gen} function. Notice that it is exactly \mintinline{ocaml}{grad_main}, but extended with annotations: \mintinline{\macocamlLexer}{macro}, \mintinline{ocaml}{<<->>}, and \mintinline{ocaml}{$-}. Further, the type of \mintinline{ocaml}{x} on line 1 (for example) is now \mintinline{ocaml}{int expr}, rather than \mintinline{ocaml}{int}. These changes provide the necessary mechanisms for code generation: on line 20, \mintinline{ocaml}{grad_gen} is used to generate \mintinline{ocaml}{(2 + (y*2)) * 2} (notice the resemblance to \mintinline{ocaml}{grad_spec}). 
% I now explain the \mintinline{ocaml}{expr} type constructor and annotations.

\begin{code}
\begin{macocamllst}
macro rec app_gen (f: diff) (x: int expr) = 
  let rec app_poly_gen (cs: int list) (x : int expr) (acc: int expr) = match cs with 
    | [] -> acc 
    | c::cs -> app_poly_gen cs x <<c + ($x * $acc)>>
  in match f with 
    | Poly(cs)      -> match cs with 
                      | [] -> <<0>>
                      | c::cs -> app_poly cs x <<c>>
    | Compose(g, h) -> app_gen h (app_gen g x)

macro rec grad_gen (f: diff) (x: int expr) = 
  let grad_poly_gen (cs: int list) (x: int expr) = 
    let grad_p c (a, b) = (c * b :: a, b + 1) 
    let (res, _) = List.fold_right grad_p cs ([], 0) in 
    app_gen Poly(remove_last res) x
  in match f with
    | Poly(cs)      -> grad_poly_gen cs x
    | Compose(g, h) -> << $(grad_main g <<x>>) * $(grad_main h (app_gen g <<x>>)) >>

let grad_spec y = $(grad_gen Compose(Poly([1 ; 2 ; 0]), Poly([2 ; 4])) <<y>>)
                   (* generates (2 + (y * 2)) * 2 *)
\end{macocamllst}
\captionof{listing}{A metaprogrammed \mintinline{ocaml}{grad_gen} function, which resembles \mintinline{ocaml}{grad_main} but generates a function resembling \mintinline{ocaml}{grad_spec}}
\label{listing:ocaml-pow-gen}
\end{code}

% Notice that \mintinline{ocaml}{pow_gen} broadly resembles \mintinline{ocaml}{pow}, with the exception of \textit{metaprogramming annotations} like \mintinline{ocaml}{<<>>} and \mintinline{ocaml}{$}. These . 
In MacoCaml, the programmer is able to generate code at compile-time, for use at run-time. I separate this into two language features:
\begin{enumerate}
  \item A type for code (\mintinline{ocaml}{'a expr}), with mechanisms (\mintinline{ocaml}{<<->>}, \mintinline{ocaml}{$-}) for creating and manipulating values of this type. Expressions that return values of code type serve as code generators.
  \item A mechanism for executing expressions \textit{at compile-time}. By using the type-system, MacoCaml ensures only code generators can be executed at compile-time. Thus compile-time evaluation will always produce code values that can be evaluated at run-time (as opposed to \mintinline{ocaml}{int}s, for example, which cannot). 
\end{enumerate}

First, in MacoCaml, code of type \mintinline{ocaml}{'a} has type \mintinline{ocaml}{'a expr}. For example, code of type \mintinline{ocaml}{int} has type \mintinline{ocaml}{int expr}. 
%   One can now write program generators that evaluate to ASTs, for example:  
% \begin{ocaml}
% let rec pow_gen (n: int) (x: int expr) = 
%   if n == 0 then Int(1) 
%   else Mul(x, (pow_gen (n-1) x))
% pow_gen 2 Int(3) (*Mul(Int(3), Mul(Int(3), Int(1)))*)
% pow_gen 2 Var(y) (*Mul(Var(y), Mul(Var(y), Int(1)))*)
% pow_gen 3 Var(y) (*Mul(Var(y), Mul(Var(y), Mul(Var(y), Int(1))))*)
% \end{ocaml}
In MacoCaml, the \mintinline{ocaml}{<<->>} (``quote'') annotation converts expressions to code values (similar to how \mintinline{ocaml}{[-]} converts expressions to list values). For example, \mintinline{ocaml}{<<1>>} has type \mintinline{ocaml}{int expr}. Under a quotation, the \mintinline{ocaml}{$-} (``splice'') annotation stops this conversion, allowing for evaluation under a quotation. For example, 

\begin{center}\mintinline{ocaml}{<<$(print_int 1+2; <<1+2>>) + 0 >>}\end{center} 

\noindent prints \mintinline{ocaml}{3} and evaluates to \mintinline{ocaml}{<<1+2+0>>}.

While not an accurate description of MacoCaml, it can be useful to think of elements of type \mintinline{ocaml}{'a expr} as abstract syntax trees (ASTs). In this conceptual model, quotation creates ASTs, by converting a program into its AST representation. For example,
\begin{center}
\text{\mintinline{ocaml}{<< x + 0 >>}} \text{ can be thought of as } \text{\mintinline{ocaml}{Plus(Var(x), Int(0))}}
\end{center}
Under a quotation, the \mintinline{ocaml}{$} annotation stops this conversion, allowing for programs that \textit{manipulate} ASTs. 
\begin{center} \text{\mintinline{ocaml}{<< $x + 0 >>}} \text{ can be thought of as } \text{\mintinline{ocaml}{Plus(x, Int(0))}}
\end{center}
Interleaving quotes and splices executes code to build ASTs
\begin{center}\text{\mintinline{ocaml}{<<$(print_int 1+2; <<1+2>>) + 0>>}} \\ 
can be thought of as \\
 \text{\mintinline{ocaml}{Plus(print_int 1+2; Plus(Int(1), Int(2)), Int(0))}} \end{center}
% Rewriting the \mintinline{ocaml}{app_gen} function in this incorrect style could be clarifying:

% \begin{ocaml}
% let rec app_gen (f: diff) (x: int ast) = 
%   let rec app_poly_gen (cs: int list) (x : int ast) (acc: int ast) = match cs with 
%     | [] -> acc 
%     | c::cs -> app_poly_gen cs x Plus(Int(c), Mul(x,acc))
%   in match f with 
%     | Poly(cs)      -> match cs with 
%                       | [] -> Int(0)
%                       | c::cs -> app_poly cs x Int(c)
%     | Compose(g, h) -> app_gen h (app_gen g x)

% app_gen Poly([2; 2]) Var(y)
%         (* Plus(Int(2), Mul(Var(y), Int(2))), or (2 + (y*2)) *)
% \end{ocaml}

Second, to evaluate expressions at compile-time, MacoCaml offers the top-level splice, a splice (\mintinline{ocaml}{$}) annotation not surrounded by quotes (\mintinline{ocaml}{<<>>}). Notice that \mintinline{ocaml}{$} is overloaded. We must be careful to disambiguate between \textbf{top-level splices}, which execute programs at compile-time, and \textbf{splices under quotations}, which stop conversion to the code type. In \Cref{listing:ocaml-pow-gen}, there is only one top-level splice, on line 20: \mintinline{ocaml}{$(grad_gen ...)}. We may now shift expressions of type \mintinline{ocaml}{'a expr} under top-level splices, to perform generation at compile time. 

Note that to access \mintinline{ocaml}{grad_gen} at compile-time, we must also move it under the top-level splice, resulting in code duplication:

\begin{macocaml}
let grad_spec y  = $(let grad_gen = ... in 
                     grad_gen Compose(Poly([1 ; 2 ; 0]), Poly([2 ; 4])) <<y>>) 
let grad_spec' y = $(let grad_gen = ... in 
                     grad_gen Compose(Poly([4; 3 ; 1 ; 7]), Poly([1 ; 8])) <<y>>) 
\end{macocaml}

To allow compile-time functions, like \mintinline{ocaml}{grad_gen}, to be re-used across multiple top-level splices, MacoCaml introduces the \mintinline{\macocamlLexer}{macro} keyword, giving us:

\begin{macocaml}
macro grad_gen = ...  
let grad_spec y  = $(grad_gen Compose(Poly([1 ; 2 ; 0]), Poly([2 ; 4])) <<y>>) 
let grad_spec' y = $(grad_gen Compose(Poly([4; 3 ; 1 ; 7]), Poly([1 ; 8])) <<y>>) 
\end{macocaml}
% To allow definitions to

% The ability to create and manipulate ASTs, combined with the ability to construct and execute functions at compile-time, allows for compile-time code generation. In the example below, we execute \mintinline{ocaml}{add_zero} at compile-time to generate the program \mintinline{ocaml}{(1*2)+0}.

% Notice that \Cref{listing:ocaml-macros} is exactly \Cref{listing:ocaml-pow-gen}. Applying this technique to the \mintinline{ocaml}{grad} example, we obtain
% \begin{macocaml}
% macro rec grad_gen f x = match f with
%   | Sin
%   | Tanh
%   | Sigmoid
%   | ...
%   | Poly(_) -> grad_of f x 
%   | Compose(f, g) -> <<$(grad_gen f x) * $(grad_gen g (app f x))>>
% let grad_fast x = $(grad_gen Compose(Tanh, Sin) <<x>>)
% \end{macocaml}
% where \mintinline{ocaml}{grad_of} and \mintinline{ocaml}{app} are appropriately modified.
\subsection{The Design Space of Metalanguages}\label{subsection:metaprogramming-design}
Different metalanguages provide slightly different variants of metaprogramming to the user. Different variants could interact differently with effect handlers. This thesis focuses on homogenous, compile-time, two-stage metaprogramming: 

\begin{enumerate}
  \item \textbf{\textsf{Homogenous or Heterogenous}}\\
         \textit{Do the generated and generating languages agree or differ?}
  
        If the generated and generating languages are the same, this is known as {homogenous} metaprogramming. Otherwise, it is {heterogenous} \citep{kiselyov-2024}.

        The metaprogramming supported by MacoCaml is homogenous, where \texttt{OCaml} code generates \texttt{OCaml} code. I focus on homogenous metaprogramming.
        %  In contrast, \texttt{MetaHaskell} \citep{mainland-2012} programs generate \texttt{C} code, allowing for heterogenous metaprogramming. 

  \item \textbf{\textsf{Run-time or Compile-Time}} \\
        \textit{When does the generation take place?}

        Code generation could take place at compile-time or at run-time.
        % (as with \texttt{MetaOCaml} \citep{kiselyov-14}). 

        % Run-time code generation may still be used to write fast and maintainable code, by adding a phase after the traditional compilation pipeline where the compiled code is executed. 
        
        Run-time and compile-time metaprogramming differ non-trivially. For example, with run-time metaprogramming, generated and generating programs may share a heap. 
        % The former requires a language construct (\mintinline{ocaml}{!}, or ``run'') for explicit invocation of the compiler. 

        In MacoCaml, code generation occurs at compile-time, and I pay no further attention to run-time metaprogramming.
        
  \item \textbf{\textsf{Two-stage or Multi-stage}} \\
  \textit{How many stages of code generation are allowed?}

  When introducing MacoCaml, I illustrated how one uses top-level splices to shift computation from run-time (``level $0$'') to compile-time (``level $-1$''). I describe levels formally in \Cref{subsection:sourcelang-type-system} (\Cref{dfn:level}, \Cpageref{dfn:level}). For now, it suffices to think of a level as a phase of evaluation: everything at level $-1$ must be fully evaluated before anything at level $0$ is evaluated. Might it be possible to shift computation from compile-time to a pre-compile-time (``level $-2$'') phase, for example, via a nested splice?
  \begin{macocaml}
$($ grad_gen f <<y>> )
  \end{macocaml}
  In a two-stage system, one is restricted to operating between two levels, so this is disallowed. In contrast, in a multi-stage system, one can operate between any number of levels. Multi-stage metaprogramming is thus strictly more general than two-stage metaprogramming.
  
  Although nested splices are disallowed in MacoCaml, it is a multi-stage system, since entire modules may be imported at a decremented level \citep{xie-2023}. However, I focus on two-stage metaprogramming. 
\end{enumerate}
  
The restriction from multi-stage to two-stage metaprogramming was motivated by a cost-benefit analysis:
\begin{enumerate}
  \item \textbf{Cost}: Since in MacoCaml, the module system is the only mechanism for achieving multi-stage programming, investigating multi-stage metaprogramming would require the investigation of module systems, effects, and metaprogramming. The interaction between module systems and metaprogramming is still an ongoing area of research \citep{chiang-2024}.
  \item \textbf{Benefit}: In practice, ``almost all uses'' of multi-stage metaprogramming only use two stages \citep{inoue-2012}. Further, scope extrusion can be observed, and is often studied, in two-stage systems \citep{isoda-24,kiselyov-16}.
\end{enumerate}